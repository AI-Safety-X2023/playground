{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverting gradient attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _Loss, CrossEntropyLoss\n",
    "from torch.optim import Optimizer, SGD, Adam, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchmetrics.functional.image import total_variation\n",
    "import torchinfo\n",
    "from image_classification.utils import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick prototyping, also consider using `ConvNet16`, a 1.6M-parameter model that is much smaller than `ResNet18`. Experiments can be made on both models or on only one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from image_classification.models import ResNet18, ConvNet16\n",
    "from image_classification.datasets import cifar10_train_test, cifar100_train_test\n",
    "from image_classification.nn import train_epoch, train_loop, train_val_loop, test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000, 5000, 5000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to 10 for CIFAR-10, 100 for CIFAR-100\n",
    "num_classes = 10\n",
    "\n",
    "# The images are already normalized by theses datasets\n",
    "if num_classes == 10:\n",
    "    get_train_test = cifar10_train_test\n",
    "elif num_classes == 100:\n",
    "    get_train_test = cifar100_train_test\n",
    "else:\n",
    "    raise ValueError(f\"Can't find CIFAR dataset with {num_classes} classes\")\n",
    "print(f\"Loading CIFAR-{num_classes}\")\n",
    "\n",
    "training_data, test_data = get_train_test(root='data')\n",
    "N_test = len(test_data)\n",
    "N_val = len(training_data) // 10\n",
    "N_aux = N_val\n",
    "N = len(training_data) - N_val - N_aux\n",
    "# This works since training data is already shuffled\n",
    "training_data, val_data, aux_data = training_data.split([N, N_val, N_aux])\n",
    "\n",
    "batch_size = 100\n",
    "N, N_val, N_aux, N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_data, batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size, drop_last=True)\n",
    "aux_loader = DataLoader(aux_data, batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 5e-4\n",
    "# For learning rate scheduling\n",
    "max_lr = 0.1\n",
    "\n",
    "epochs = 6\n",
    "steps_per_epoch = N // batch_size\n",
    "\n",
    "lr_sched_params = dict(max_lr=max_lr, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "top_k = {10: 1, 100: 5}[num_classes]\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=num_classes, top_k=top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer (TODO: compare SGD & Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model: nn.Module, opt_name='adamw', lr=lr, weight_decay=weight_decay, **kwargs) -> Optimizer:\n",
    "    cls = {'sgd': SGD, 'adam': Adam, 'adamw': AdamW}[opt_name]\n",
    "    return cls(model.parameters(), lr=lr, weight_decay=weight_decay, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing reconstruction attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_input_image(input: Tensor, label: Tensor, title='', cmap=None, ax: plt.Axes = None):\n",
    "    \"\"\"\n",
    "    Displays an an input image to a neural network.\n",
    "\n",
    "    `input`: a 3D tensor\n",
    "    `cmap`: grayscale by default.\n",
    "    \"\"\"\n",
    "    decoders = {\n",
    "        10: training_data.decode_cifar10_image,\n",
    "        100: training_data.decode_cifar100_image,\n",
    "    }\n",
    "    image = decoders[len(training_data.classes)](input)\n",
    "    class_ = training_data.decode_target(label)\n",
    "\n",
    "    if ax is None:\n",
    "        _fig, ax = plt.subplots()\n",
    "    ax.imshow(image, cmap=cmap, interpolation='nearest')\n",
    "    if title:\n",
    "        title = f\"{class_} - {title}\"\n",
    "    else:\n",
    "        title = class_\n",
    "    ax.set_title(title, fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: use ConvNet16 and small dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification.nn import Metric, MetricLogger, _detect_device\n",
    "import federated\n",
    "from federated import Aggregator, Mean, Krum\n",
    "import torchjd\n",
    "from torchjd.aggregation import Aggregator, Mean, Krum\n",
    "\n",
    "def train_epoch_jd(\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        criterion: _Loss,\n",
    "        optimizer: Optimizer,\n",
    "        aggregator: Aggregator,\n",
    "        keep_pbars=True,\n",
    "        metric: Metric = None,\n",
    "    ):\n",
    "    device = _detect_device(model)\n",
    "    model.train()\n",
    "    criterion.reduction = 'none'\n",
    "\n",
    "    logger = MetricLogger(\n",
    "        metric,\n",
    "        desc='Train loop', total=len(dataloader.dataset), keep_pbars=keep_pbars,\n",
    "    )\n",
    "\n",
    "    for step, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        #logits = model(X).detach_()\n",
    "        #losses = criterion(logits, y)\n",
    "        logits = model(X)\n",
    "\n",
    "        losses = criterion(logits, y)\n",
    "        mean_loss = losses.mean().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #federated.naive_backpropagate_grads(model, X, y, criterion, aggregator)\n",
    "        #federated.backward(losses, model, aggregator)\n",
    "        #federated.backpropagate_grads(model, X, y, criterion, aggregator)\n",
    "        torchjd.backward(losses, aggregator)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logger.compute_metrics(X, y, logits, mean_loss)\n",
    "    \n",
    "    criterion.reduction = 'mean'\n",
    "    logger.finish()\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "\n",
    "def train_val_loop_jd(\n",
    "        model: nn.Module,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "        criterion: _Loss,\n",
    "        optimizer: Optimizer,\n",
    "        aggregator: Aggregator,\n",
    "        epochs: int,\n",
    "        *,\n",
    "        lr_scheduler: LRScheduler = None,\n",
    "        keep_pbars=True,\n",
    "        metric: Metric = None,\n",
    "        validate_every: int = 2,\n",
    "        early_stopping = True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Run the training loop on the model with periodic validation.\n",
    "\n",
    "    If `val_dataloader` is `None`, no validation is performed.\n",
    "\n",
    "    If `early_stopping` is True, the training loop exits when validation loss starts decreasing.\n",
    "    \"\"\"\n",
    "    val_loss = float('inf')\n",
    "    for epoch in trange(epochs, desc='Train epochs', unit='epoch', leave=keep_pbars):\n",
    "        train_epoch_jd(\n",
    "            model, train_dataloader, criterion, optimizer, aggregator,\n",
    "            keep_pbars=keep_pbars, metric=metric,\n",
    "        )\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        if val_dataloader is not None and epoch % validate_every == 0:\n",
    "            logger = test_epoch(\n",
    "                model, val_dataloader, criterion,\n",
    "                keep_pbars=keep_pbars, metric=metric,\n",
    "            )\n",
    "            next_val_loss = logger.avg_loss.compute()\n",
    "            if early_stopping and next_val_loss > val_loss:\n",
    "                print(f\"Epoch {epoch}: validation loss stopped improving, exiting train loop.\")\n",
    "                break\n",
    "            val_loss = next_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import image_classification.models\n",
    "reload(federated)\n",
    "reload(image_classification.models)\n",
    "from image_classification.models import ShuffleNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc9c42b5bb3402db128ad93924445ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/6 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec705f3b1d6f4c85813052bd441f1d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [08:23<00:00, 79.39it/s, MulticlassAccuracy=0.462, avg_loss=1.77]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21894097d80549b49ad0bddded4ea212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 9807.75it/s, MulticlassAccuracy=0.336, avg_loss=1.57]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0ac488dd8840e5b98575a6950bfb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m aggregator = Mean()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Pretrain the model to make it learn the features\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#mini_train_set = Subset(training_data, np.arange(N_aux))\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#mini_train_loader = DataLoader(mini_train_set, batch_size=64)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_val_loop_jd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m;\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_val_loop_jd\u001b[39m\u001b[34m(model, train_dataloader, val_dataloader, criterion, optimizer, aggregator, epochs, lr_scheduler, keep_pbars, metric, validate_every, early_stopping)\u001b[39m\n\u001b[32m     25\u001b[39m val_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(epochs, desc=\u001b[33m'\u001b[39m\u001b[33mTrain epochs\u001b[39m\u001b[33m'\u001b[39m, unit=\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m, leave=keep_pbars):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mtrain_epoch_jd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_pbars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_pbars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     32\u001b[39m         lr_scheduler.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain_epoch_jd\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, aggregator, keep_pbars, metric)\u001b[39m\n\u001b[32m     36\u001b[39m optimizer.zero_grad()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m#federated.naive_backpropagate_grads(model, X, y, criterion, aggregator)\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#federated.backward(losses, model, aggregator)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m#federated.backpropagate_grads(model, X, y, criterion, aggregator)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mtorchjd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m optimizer.step()\n\u001b[32m     44\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/backward.py:98\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, aggregator, inputs, retain_graph, parallel_chunk_size)\u001b[39m\n\u001b[32m     94\u001b[39m accumulate = Accumulate(inputs)\n\u001b[32m     96\u001b[39m backward_transform = accumulate << aggregate << jac << diag << init\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mbackward_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEmptyTensorDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:81\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m     80\u001b[39m     intermediate = \u001b[38;5;28mself\u001b[39m.inner(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:81\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m     80\u001b[39m     intermediate = \u001b[38;5;28mself\u001b[39m.inner(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping similar frames: Transform.__call__ at line 48 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:81\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m     80\u001b[39m     intermediate = \u001b[38;5;28mself\u001b[39m.inner(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:80\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     intermediate = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outer(intermediate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/aggregate.py:27\u001b[39m, in \u001b[36mAggregate._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Jacobians) -> Gradients:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:81\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m     80\u001b[39m     intermediate = \u001b[38;5;28mself\u001b[39m.inner(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:80\u001b[39m, in \u001b[36mComposition._compute\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _A) -> _C:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     intermediate = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outer(intermediate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/base.py:48\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: _B) -> _C:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28minput\u001b[39m.check_keys_are(\u001b[38;5;28mself\u001b[39m.required_keys)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/aggregate.py:54\u001b[39m, in \u001b[36m_AggregateMatrices._compute\u001b[39m\u001b[34m(self, jacobian_matrices)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03mConcatenates the provided ``jacobian_matrices`` into a single matrix and aggregates it using\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03mthe ``aggregator``. Returns the dictionary mapping each key from ``jacobian_matrices`` to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m    dimension of each jacobian matrix should be the same.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m ordered_matrices = \u001b[38;5;28mself\u001b[39m._select_ordered_subdict(jacobian_matrices, \u001b[38;5;28mself\u001b[39m.key_order)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/autojac/_transform/aggregate.py:88\u001b[39m, in \u001b[36m_AggregateMatrices._aggregate_group\u001b[39m\u001b[34m(jacobian_matrices, aggregator)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EmptyTensorDict()\n\u001b[32m     87\u001b[39m united_jacobian_matrix = _AggregateMatrices._unite(jacobian_matrices)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m united_gradient_vector = \u001b[43maggregator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munited_jacobian_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m gradient_vectors = _AggregateMatrices._disunite(united_gradient_vector, jacobian_matrices)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gradient_vectors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/aggregation/bases.py:36\u001b[39m, in \u001b[36mAggregator.__call__\u001b[39m\u001b[34m(self, matrix)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, matrix: Tensor) -> Tensor:\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Computes the aggregation from the input matrix and applies all registered hooks.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torchjd/aggregation/bases.py:91\u001b[39m, in \u001b[36m_WeightedAggregator.forward\u001b[39m\u001b[34m(self, matrix)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28mself\u001b[39m._check_is_matrix(matrix)\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._check_is_finite(matrix)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweighting\u001b[49m(matrix)\n\u001b[32m     92\u001b[39m vector = \u001b[38;5;28mself\u001b[39m.combine(matrix, weights)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vector\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1915\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1912\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1913\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1914\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1916\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1917\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#net = ResNet18(num_classes=num_classes).to(device)\n",
    "net = ShuffleNetV2().to(device)\n",
    "opt = make_optimizer(net, opt_name='adam', lr=lr)\n",
    "aggregator = Mean()\n",
    "\n",
    "# Pretrain the model to make it learn the features\n",
    "#mini_train_set = Subset(training_data, np.arange(N_aux))\n",
    "#mini_train_loader = DataLoader(mini_train_set, batch_size=64)\n",
    "\n",
    "train_val_loop_jd(\n",
    "    net, train_loader, val_loader,\n",
    "    criterion, opt, aggregator,\n",
    "    epochs,\n",
    "    metric=metric\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de563d33fc6749958e1d7c4705c967ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/6 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569570e6792f443181cb0a12eb294219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:08<00:00, 4598.58it/s, MulticlassAccuracy=0.496, avg_loss=1.77]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fddb42228234c07abe2f2b759aa7147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 11216.66it/s, MulticlassAccuracy=0.348, avg_loss=1.55]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf9dbbe60fe4be386a3c4627c42fd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:08<00:00, 4493.70it/s, MulticlassAccuracy=0.528, avg_loss=1.42]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1816403c61164b298d81e4c34a7b3fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:09<00:00, 4346.30it/s, MulticlassAccuracy=0.687, avg_loss=1.21]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cb12c275a242edb314ec621d429c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 11070.12it/s, MulticlassAccuracy=0.591, avg_loss=1.16]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc474c3ef5de4c9ab45fa513c74357af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:08<00:00, 4608.30it/s, MulticlassAccuracy=0.724, avg_loss=1.05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123a4f81785a4519bc60918bf796633b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:09<00:00, 4309.65it/s, MulticlassAccuracy=0.789, avg_loss=0.939]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf7dae0a8a94f309ba95da3b24753db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 11205.96it/s, MulticlassAccuracy=0.595, avg_loss=1.08]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0212eb8fb467431c80a81d505a8dabb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:09<00:00, 4230.92it/s, MulticlassAccuracy=0.79, avg_loss=0.854]\n"
     ]
    }
   ],
   "source": [
    "#net = ResNet18(num_classes=num_classes).to(device)\n",
    "net = ShuffleNetV2().to(device)\n",
    "opt = make_optimizer(net, opt_name='adam', lr=lr)\n",
    "\n",
    "# Pretrain the model to make it learn the features\n",
    "#mini_train_set = Subset(training_data, np.arange(N_aux))\n",
    "#mini_train_loader = DataLoader(mini_train_set, batch_size=64)\n",
    "\n",
    "train_val_loop(\n",
    "    net, train_loader, val_loader,\n",
    "    criterion, opt, epochs, metric=metric\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185448a2eb7c415788f19318da69bfd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m mini_train_set = Subset(training_data, np.arange(N_aux))\n\u001b[32m      5\u001b[39m mini_train_loader = DataLoader(mini_train_set, batch_size)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/ml/psc/playground/implementations/projects/poisoning/image_classification/nn.py:84\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, loss_fn, optimizer, keep_pbars, metric)\u001b[39m\n\u001b[32m     82\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m loss = loss_fn(logits, y)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/ml/psc/playground/implementations/projects/poisoning/image_classification/cifar_models/resnet.py:99\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     97\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer1(out)\n\u001b[32m     98\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer2(out)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m out = \u001b[38;5;28mself\u001b[39m.layer4(out)\n\u001b[32m    101\u001b[39m out = F.avg_pool2d(out, \u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/ml/psc/playground/implementations/projects/poisoning/image_classification/cifar_models/resnet.py:36\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     35\u001b[39m     out = F.relu(\u001b[38;5;28mself\u001b[39m.bn1(\u001b[38;5;28mself\u001b[39m.conv1(x)))\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     37\u001b[39m     out += \u001b[38;5;28mself\u001b[39m.shortcut(x)\n\u001b[32m     38\u001b[39m     out = F.relu(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/ml-TQx6uCZG/lib/python3.13/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "net = ResNet18(num_classes=num_classes).to(device)\n",
    "opt = make_optimizer(net, opt_name='adam', lr=lr)\n",
    "# Pretrain the model to make it learn the features\n",
    "mini_train_set = Subset(training_data, np.arange(N_aux))\n",
    "mini_train_loader = DataLoader(mini_train_set, batch_size)\n",
    "train_epoch(\n",
    "    net, mini_train_loader,\n",
    "    criterion, opt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
