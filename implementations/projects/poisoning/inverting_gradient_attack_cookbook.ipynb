{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverting gradient attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the inverting gradient data poisoning attack by [Bouaziz et al.](https://arxiv.org/abs/2410.21453) We compare the effectiveness of machine unlearning as a defense, with a robust gradient aggregation rule.\n",
    "\n",
    "We consider the same machine unlearning algorithms tested by [Pawelczyk et al.](https://arxiv.org/abs/2406.17216) and we use the $m$-KRUM aggregator introduced by [Blanchard et al.](https://arxiv.org/abs/1703.02757)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from copy import deepcopy\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.modules.loss import _Loss, CrossEntropyLoss\n",
    "from torch.optim import Optimizer, SGD, Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from image_classification.nn import Logs, test_epoch\n",
    "from image_classification.accel import BEST_DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base learning settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "For quick prototyping, also consider using [`ShuffleNetV2`](https://arxiv.org/abs/1807.11164v1), a 300M-parameter model that is much smaller than [`ResNet18`](https://arxiv.org/abs/1704.06904). Experiments can be made on both models or on only one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification.models import ResNet18, ShuffleNetV2\n",
    "from image_classification.datasets import cifar10_train_test, cifar100_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We use CIFAR-10 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000, 5000, 5000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to 10 for CIFAR-10, 100 for CIFAR-100\n",
    "num_classes = 10\n",
    "\n",
    "# The images are already normalized by these datasets\n",
    "if num_classes == 10:\n",
    "    get_train_test = cifar10_train_test\n",
    "elif num_classes == 100:\n",
    "    get_train_test = cifar100_train_test\n",
    "else:\n",
    "    raise ValueError(f\"Can't find CIFAR dataset with {num_classes} classes\")\n",
    "print(f\"Loading CIFAR-{num_classes}\")\n",
    "\n",
    "training_data, test_data = get_train_test(root='data')\n",
    "N_test = len(test_data)\n",
    "N_val = len(training_data) // 10\n",
    "N_aux = N_val\n",
    "N = len(training_data) - N_val - N_aux\n",
    "# This works since training data is already shuffled\n",
    "training_data, val_data, aux_data = training_data.split([N, N_val, N_aux])\n",
    "\n",
    "batch_size = 100\n",
    "N, N_val, N_aux, N_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_data, batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size, drop_last=True)\n",
    "aux_loader = DataLoader(aux_data, batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverting gradient attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification.gradient_attack import (\n",
    "    GradientAttack,\n",
    "    GradientEstimator, OmniscientGradientEstimator, ShadowGradientEstimator,\n",
    "    SampleInit, SampleInitRandomNoise, LearningSettings, GradientInverter,\n",
    "    Schedule, NeverUpdate\n",
    ")\n",
    "from inverting_gradient_attack import Pipeline, PipelineResults, Unlearning, Hyperparams\n",
    "import federated as fed\n",
    "#from federated import Aggregator, Mean, Krum\n",
    "from inverting_gradient_attack import Aggregator, Mean, Krum # Avoids failing isinstance checks\n",
    "from federated.utils import convert_bn_modules_to_gn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisoning + Unlearning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_network(network_factory: type[nn.Module]):\n",
    "    \"\"\"Patches a neural network factory to make it compatible to per-gradient backpropagation.\n",
    "    \n",
    "    This replaces a model's BatchNorm layers with GroupNorm.\n",
    "    See `federated.utils` documentation for technical details.\n",
    "    \"\"\"\n",
    "    def patch():\n",
    "        return convert_bn_modules_to_gn(network_factory())\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model: nn.Module) -> float:\n",
    "    \"\"\"Compute the model accuracy on the test set.\"\"\"\n",
    "    metric = MulticlassAccuracy(num_classes)\n",
    "    logger = test_epoch(\n",
    "        model,\n",
    "        test_loader,\n",
    "        criterion,\n",
    "        metric=metric,\n",
    "    )\n",
    "    return logger.metrics['MulticlassAccuracy'].compute().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(\n",
    "        model_factory = ResNet18,\n",
    "        aggregator = Mean(),\n",
    "        inversion_method: GradientAttack | None = None,\n",
    "        poison_factor: float = 0.2,\n",
    "        unlearning_method: Unlearning | None = None,\n",
    "        training_hparams: dict = {},\n",
    "        unlearning_hparams: dict = {},\n",
    "        quicktesting: bool = False,\n",
    "    ) -> tuple[nn.Module, PipelineResults]:\n",
    "    \"\"\"Run a training pipeline with default settings.\n",
    "\n",
    "    The training may include poisoning with an inverting gradient attack,\n",
    "    and perform unlearning after training.\n",
    "\n",
    "    Parameters:\n",
    "        model_factory (Module type): the neural network class.\n",
    "        aggregator (Aggregator): a gradient aggregation method.\n",
    "        inversion_method (GradientAttack, optional): the gradient inversion method.\n",
    "        poison_factor (float, optional): the proportion of poisons in the training data.\n",
    "        unlearning_method (Unlearning, optional): the unlearning algorithm.\n",
    "\n",
    "        training_hparams (dict, optional): training hyperparameter overrides.\n",
    "        unlearning_hparams (dict, optional): unlearning hyperparameter overrides.\n",
    "\n",
    "        quicktesting (bool, defaults to False): whether to use a small model,\n",
    "            a smaller subset of the training dataset and less training epochs\n",
    "            for quicker testing iterations. Overrides hyperparameters when relevant.\n",
    "\n",
    "    Returns:\n",
    "        out (tuple[nn.Module, PipelineResults]): the trained and possibly unlearned model\n",
    "            and the pipeline results.\n",
    "    \"\"\"\n",
    "    poisoning = inversion_method is not None\n",
    "    unlearning = unlearning_method is not None\n",
    "\n",
    "    if poisoning:\n",
    "        inverter = GradientInverter(\n",
    "            method = inversion_method,\n",
    "            estimator = ShadowGradientEstimator(aux_loader),\n",
    "            steps = 5,\n",
    "            sample_init = SampleInitRandomNoise(training_data),\n",
    "        )\n",
    "    \n",
    "    settings = LearningSettings(\n",
    "        criterion,\n",
    "        aggregator = deepcopy(aggregator),\n",
    "        num_clean = batch_size,\n",
    "        num_byzantine = int(poison_factor / (1. - poison_factor) * batch_size),\n",
    "    )\n",
    "\n",
    "    hparams = Hyperparams(batch_size=batch_size, num_classes=num_classes)\n",
    "    hparams = dataclasses.replace(hparams, **training_hparams)\n",
    "\n",
    "    if quicktesting:\n",
    "        model_factory = ShuffleNetV2\n",
    "        mini_train_set, _ = random_split(training_data, [0.1, 0.9])\n",
    "        train_loader_ = DataLoader(mini_train_set, batch_size)\n",
    "        hparams = dataclasses.replace(hparams, epochs=1)\n",
    "        if poisoning:\n",
    "            inverter.steps = 1\n",
    "    else:\n",
    "        train_loader_ = train_loader\n",
    "\n",
    "    pipeline = Pipeline(settings, train_loader_, val_loader, hparams)\n",
    "    if unlearning:\n",
    "        pipeline.unlearning_hparams[unlearning_method].update(unlearning_hparams)\n",
    "    print(pipeline)\n",
    "\n",
    "    model = patch_network(model_factory)().to(BEST_DEVICE)\n",
    "\n",
    "    if poisoning and unlearning:\n",
    "        unlearner, results = pipeline.poison_and_unlearn(model, inverter, unlearning_method)\n",
    "        model = unlearner\n",
    "    elif poisoning:\n",
    "        poisoned, results = pipeline.poison(model, inverter)\n",
    "        model = poisoned\n",
    "    else:\n",
    "        assert not unlearning, \"Cannot unlearn when there is no poisoning\"\n",
    "        trained, results = pipeline.train(model)\n",
    "        model = trained \n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        model_factory = ResNet18,\n",
    "        aggregator = Mean(),\n",
    "        training_hparams: dict = {},\n",
    "        quicktesting: bool = False,\n",
    ") -> tuple[nn.Module, PipelineResults]:\n",
    "    \"\"\"Train the model normally.\n",
    "    \n",
    "    See `run_pipeline` for details on the arguments.\n",
    "    \"\"\"\n",
    "    return run_pipeline(\n",
    "        model_factory,\n",
    "        aggregator=aggregator,\n",
    "        poison_factor=0.0,\n",
    "        training_hparams=training_hparams,\n",
    "        quicktesting=quicktesting,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with data poisoning\n",
    "\n",
    "This inverting gradient data poisoning attack can be defended by changing the aggregator to KRUM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison(\n",
    "        model_factory = ResNet18,\n",
    "        aggregator = Mean(),\n",
    "        inversion_method = GradientAttack.ASCENT,\n",
    "        poison_factor: float = 0.2,\n",
    "        training_hparams: dict = {},\n",
    "        quicktesting: bool = False,\n",
    "    ) -> tuple[nn.Module, PipelineResults]:\n",
    "    \"\"\"Run the poisoning pipeline with default settings.\n",
    "\n",
    "    See `run_pipeline` for details on the arguments.\n",
    "    \"\"\"\n",
    "    return run_pipeline(\n",
    "        model_factory,\n",
    "        aggregator=aggregator,\n",
    "        inversion_method=inversion_method,\n",
    "        poison_factor=poison_factor,\n",
    "        training_hparams=training_hparams,\n",
    "        quicktesting=quicktesting,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning and then Unlearning\n",
    "\n",
    "Machine unlearning is used against a gradient inversion data poisoning attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_and_unlearn(\n",
    "        model_factory = ResNet18,\n",
    "        aggregator = Mean(),\n",
    "        inversion_method = GradientAttack.ASCENT,\n",
    "        poison_factor: float = 0.2,\n",
    "        unlearning_method = Unlearning.NEG_GRAD_PLUS,\n",
    "        training_hparams: dict = {},\n",
    "        unlearning_hparams: dict = {},\n",
    "        quicktesting: bool = False,\n",
    "    ) -> tuple[nn.Module, PipelineResults]:\n",
    "    \"\"\"Run the poison-and-unlearn pipeline with default settings.\n",
    "\n",
    "    See `run_pipeline` for details on the arguments.\n",
    "    \"\"\"\n",
    "    return run_pipeline(\n",
    "        model_factory,\n",
    "        aggregator=aggregator,\n",
    "        inversion_method=inversion_method,\n",
    "        poison_factor=poison_factor,\n",
    "        unlearning_method=unlearning_method,\n",
    "        training_hparams=training_hparams,\n",
    "        unlearning_hparams=unlearning_hparams,\n",
    "        quicktesting=quicktesting,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing $m$-Krum's utility\n",
    "\n",
    "We study the effect of using a robust aggregator on the model's test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_krum(\n",
    "        model_factory: type[nn.Module],\n",
    "        training_hparams = dict(epochs=1),\n",
    "        n_points: int = 11,\n",
    "    ) -> tuple[float, pd.DataFrame]:\n",
    "\n",
    "    def baseline() -> float:\n",
    "        model, _ = train(\n",
    "            model_factory,\n",
    "            aggregator = Mean(),\n",
    "            training_hparams = training_hparams,\n",
    "            quicktesting=False,\n",
    "        )\n",
    "        return compute_accuracy(model)\n",
    "    \n",
    "    def eval_krum_with_poison_factor(tol: float) -> float:\n",
    "        model, _ = train(\n",
    "            model_factory,\n",
    "            aggregator = Krum.with_learning_settings(batch_size, tol),\n",
    "            training_hparams = training_hparams,\n",
    "            quicktesting=False,\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "        return compute_accuracy(model)\n",
    "        \n",
    "    base_acc = baseline()\n",
    "\n",
    "    x_f = np.linspace(0.0, 0.4, n_points)\n",
    "    y_accuracy = np.vectorize(eval_krum_with_poison_factor)(x_f)\n",
    "\n",
    "    df = pd.DataFrame({'f': x_f, 'accuracy': y_accuracy})\n",
    "    return base_acc, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22883485be54654a2940fbc120e8d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_acc, x_f_y_acc = assess_krum(ShuffleNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_krum_assessment(base_acc: float, x_f_y_acc: pd.DataFrame):\n",
    "    # TODO: error bars + statistical test\n",
    "    x_f = x_f_y_acc['f']\n",
    "    y_accuracy = x_f_y_acc['accuracy']\n",
    "    plt.hlines(base_acc, min(x_f), max(x_f), label=\"mean aggregation\", colors='orange')\n",
    "\n",
    "    plt.scatter(x_f, y_accuracy, label=r\"$f$-resilient multi-Krum\")\n",
    "    plt.xlabel(r\"$f$ (Byzantine proportion)\")\n",
    "    plt.ylabel(r\"accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(r\"Impact of multi-Krum on the test accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_krum_assessment(base_acc, x_f_y_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy (mean): 0.389\n",
      "Krum accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.3992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.4403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.4186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.4213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.3802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.3877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f  accuracy\n",
       "0   0.00    0.4177\n",
       "1   0.04    0.3790\n",
       "2   0.08    0.3852\n",
       "3   0.12    0.3992\n",
       "4   0.16    0.4092\n",
       "5   0.20    0.3883\n",
       "6   0.24    0.4403\n",
       "7   0.28    0.4186\n",
       "8   0.32    0.4213\n",
       "9   0.36    0.3802\n",
       "10  0.40    0.3877"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Base accuracy (mean): {base_acc:.3}\")\n",
    "print(f\"Krum accuracy:\")\n",
    "x_f_y_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no poisoning, Krum incurs a minimal accuracy decrease (~3%) even in the most pessimistic learning settings. Since the accuracy also increases, we can tell with high statistical confidence that Krum does not decrease accuracy by a significant amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poison selection rate\n",
    "\n",
    "We test GA, OG and LIE against $m$-Krum to compute the poison selection rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_krum_selection_rate(\n",
    "        model_factory: type[nn.Module],\n",
    "        alpha: float,\n",
    "        tol: float,\n",
    "        method: GradientAttack,\n",
    "        quicktesting: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Compute Krum poison selection rate.\"\"\"\n",
    "    num_clean = batch_size\n",
    "    num_byzantine = int(alpha / (1. - alpha) * num_clean)\n",
    "    _, poison_results = poison(\n",
    "        model_factory,\n",
    "        aggregator = Krum.with_learning_settings(num_clean, tol),\n",
    "        inversion_method = method,\n",
    "        poison_factor = alpha,\n",
    "        training_hparams = dict(epochs=1),\n",
    "        quicktesting=quicktesting,\n",
    "    )\n",
    "    clear_output()\n",
    "    num_selected_poisons = torch.cat([\n",
    "        per_epoch['num_selected_poisons'].compute()\n",
    "        for per_epoch in poison_results.train_logs.train_metrics\n",
    "    ])\n",
    "    return (num_selected_poisons / num_byzantine).numpy(force=True)\n",
    "\n",
    "def compute_selection_rate_table(\n",
    "        model_factory: type[nn.Module],\n",
    "        quicktesting: bool = True,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"Compute a poison selection rate table per model, poison factor, Krum tolerance.\"\"\"\n",
    "    poison_factor = np.array([0.01, 0.05, 0.1, 0.2, 0.3, 0.4])\n",
    "    tolerance = np.array([0.1]) #np.array([0.01, 0.05, 0.1, 0.2, 0.3, 0.4])\n",
    "    atk_method = [\n",
    "        GradientAttack.ASCENT,\n",
    "        GradientAttack.ORTHOGONAL,\n",
    "        #GradientAttack.LITTLE_IS_ENOUGH,\n",
    "    ]\n",
    "    rows = []\n",
    "    for alpha in poison_factor:\n",
    "        for tol in tolerance:\n",
    "            for method in atk_method:\n",
    "                selection_rate = eval_krum_selection_rate(\n",
    "                    model_factory, alpha, tol, method,\n",
    "                    quicktesting=quicktesting,\n",
    "                )\n",
    "                rows.append((alpha, tol, str(method), selection_rate.mean()))\n",
    "    return pd.DataFrame(\n",
    "        rows,\n",
    "        columns=['poison_factor', 'tolerance', 'attack_method', 'average_selection_rate'],\n",
    "    )\n",
    "\n",
    "def display_selection_rate(\n",
    "        selection_rate: np.ndarray,\n",
    "        alpha: float,\n",
    "        tol: float,\n",
    "        method: GradientAttack,\n",
    "    ):\n",
    "    avg_selection_rate = selection_rate.mean()\n",
    "\n",
    "    plt.scatter(selection_rate)\n",
    "    plt.hlines(avg_selection_rate, 0, len(selection_rate), colors='orange')\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Poison selection rate\")\n",
    "    plt.title(f\"{method} Poison selection rate by Krum\")\n",
    "    plt.suptitle(fr\"Krum resilience: {tol:.2}, true poison ratio: {alpha:.2}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha = 0.2\n",
    "#tol = 0.1\n",
    "#method = GradientAttack.LITTLE_IS_ENOUGH\n",
    "#selection_rate = eval_krum_selection_rate(\n",
    "#    ShuffleNetV2,\n",
    "#    alpha=alpha, tol=tol, method=method,\n",
    "#    quicktesting=True,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_selection_rate(selection_rate, alpha, tol, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poison_factor</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>attack_method</th>\n",
       "      <th>average_selection_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Gradient Ascent</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Orthogonal Gradient</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    poison_factor  tolerance        attack_method  average_selection_rate\n",
       "0            0.01        0.1      Gradient Ascent                   0.750\n",
       "1            0.01        0.1  Orthogonal Gradient                   0.950\n",
       "2            0.05        0.1      Gradient Ascent                   0.975\n",
       "3            0.05        0.1  Orthogonal Gradient                   1.000\n",
       "4            0.10        0.1      Gradient Ascent                   1.000\n",
       "5            0.10        0.1  Orthogonal Gradient                   1.000\n",
       "6            0.20        0.1      Gradient Ascent                   1.000\n",
       "7            0.20        0.1  Orthogonal Gradient                   1.000\n",
       "8            0.30        0.1      Gradient Ascent                   1.000\n",
       "9            0.30        0.1  Orthogonal Gradient                   1.000\n",
       "10           0.40        0.1      Gradient Ascent                   1.000\n",
       "11           0.40        0.1  Orthogonal Gradient                   1.000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_rate_table = compute_selection_rate_table(ShuffleNetV2, quicktesting=True)\n",
    "selection_rate_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No poisoning + no defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(settings=LearningSettings(criterion=CrossEntropyLoss(), aggregator=Mean(), num_clean=100, num_byzantine=0), train_loader=Dataloader(<len=40000>), val_loader=Dataloader(<len=5000>), hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()), unlearning_hparams={<Unlearning.GRADIENT_DESCENT: 0>: {'lr': 0.001, 'epochs': 1}, <Unlearning.NOISY_GRADIENT_DESCENT: 2>: {'lr': 0.001, 'epochs': 1, 'noise_scale': 0.00031622776601683794}, <Unlearning.GRADIENT_ASCENT: 1>: {'lr': 1e-05, 'epochs': 1}, <Unlearning.NEG_GRAD_PLUS: 3>: {'lr': 0.001, 'beta': 0.999, 'epochs': 1}, <Unlearning.CFK: 4>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.EUK: 5>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.SCRUB: 6>: {'max_steps': 1, 'steps': 1, 'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9}})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af9ed304b8b4a4da562980cea6234a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e4fb80026c4ef8bd5895c7a87a3456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:09<00:00, 4026.43it/s, accuracy=0.418, avg_loss=1.94]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7ff4eabdd0496485e34afafdaa948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 10896.51it/s, accuracy=0.414, avg_loss=1.69]\n"
     ]
    }
   ],
   "source": [
    "model, train_results = train(\n",
    "    ShuffleNetV2,\n",
    "    aggregator = Mean(),\n",
    "    training_hparams = dict(epochs=1),\n",
    "    quicktesting=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.40209999680519104"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No poisoning + Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(settings=LearningSettings(criterion=CrossEntropyLoss(), aggregator=Krum(num_byzantine=11, num_selected=86), num_clean=100, num_byzantine=0), train_loader=Dataloader(<len=40000>), val_loader=Dataloader(<len=5000>), hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()), unlearning_hparams={<Unlearning.GRADIENT_DESCENT: 0>: {'lr': 0.001, 'epochs': 1}, <Unlearning.NOISY_GRADIENT_DESCENT: 2>: {'lr': 0.001, 'epochs': 1, 'noise_scale': 0.00031622776601683794}, <Unlearning.GRADIENT_ASCENT: 1>: {'lr': 1e-05, 'epochs': 1}, <Unlearning.NEG_GRAD_PLUS: 3>: {'lr': 0.001, 'beta': 0.999, 'epochs': 1}, <Unlearning.CFK: 4>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.EUK: 5>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.SCRUB: 6>: {'max_steps': 1, 'steps': 1, 'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9}})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad05552c02b469b80e31331db7e20c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a912fd4b4844812b6c0b24207832e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loop: 100%|██████████| 40000/40000 [00:10<00:00, 3978.87it/s, accuracy=0.427, avg_loss=1.94]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ab7d852c234c80a884488e771a2626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 10896.83it/s, accuracy=0.365, avg_loss=1.63]\n"
     ]
    }
   ],
   "source": [
    "model, train_results = train(\n",
    "    ShuffleNetV2,\n",
    "    aggregator = Krum.with_learning_settings(batch_size, tol = 0.05),\n",
    "    training_hparams = dict(epochs=1),\n",
    "    quicktesting=False, # quicktesting=True gives bad results (model outputs constant???)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4125000238418579"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning + no defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(settings=LearningSettings(criterion=CrossEntropyLoss(), aggregator=Mean(), num_clean=100, num_byzantine=5), train_loader=Dataloader(<len=40000>), val_loader=Dataloader(<len=5000>), hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()), unlearning_hparams={<Unlearning.GRADIENT_DESCENT: 0>: {'lr': 0.001, 'epochs': 1}, <Unlearning.NOISY_GRADIENT_DESCENT: 2>: {'lr': 0.001, 'epochs': 1, 'noise_scale': 0.00031622776601683794}, <Unlearning.GRADIENT_ASCENT: 1>: {'lr': 1e-05, 'epochs': 1}, <Unlearning.NEG_GRAD_PLUS: 3>: {'lr': 0.001, 'beta': 0.999, 'epochs': 1}, <Unlearning.CFK: 4>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.EUK: 5>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.SCRUB: 6>: {'max_steps': 1, 'steps': 1, 'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9}})\n",
      "Poisoning GradientInverter(method=Gradient Ascent, estimator=ShadowGradientEstimator(aux_loader = DataLoader(<data_len=5000>)), steps=5, tv_coef=0.0, lr=0.3, sample_init=SampleInitRandomNoise(), label_update_schedule=PowerofTwoSchedule()) with hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788b305055124accbd95ae9c76fe4a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c79da94fb254d4faf851a54fe9311df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test epoch:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 100%|██████████| 5000/5000 [00:00<00:00, 10822.65it/s, accuracy=0.369, avg_loss=1.66]\n"
     ]
    }
   ],
   "source": [
    "poisoned_no_defense, poison_no_defense_results = poison(\n",
    "    ShuffleNetV2,\n",
    "    aggregator = Mean(),\n",
    "    inversion_method = GradientAttack.ASCENT,\n",
    "    poison_factor = 0.05,\n",
    "    training_hparams = dict(epochs=1),\n",
    "    quicktesting=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poisoned_no_defense, poison_no_defense_results = poison(\n",
    "#    ShuffleNetV2,\n",
    "#    aggregator = Krum.with_learning_settings(batch_size, 0.05),\n",
    "#    inversion_method = GradientAttack.LITTLE_IS_ENOUGH,\n",
    "#    poison_factor = 0.05,\n",
    "#    training_hparams = dict(epochs=1),\n",
    "#    quicktesting=False,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning + Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(settings=LearningSettings(criterion=CrossEntropyLoss(), aggregator=Krum(num_byzantine=11, num_selected=86), num_clean=100, num_byzantine=5), train_loader=Dataloader(<len=40000>), val_loader=Dataloader(<len=5000>), hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()), unlearning_hparams={<Unlearning.GRADIENT_DESCENT: 0>: {'lr': 0.001, 'epochs': 1}, <Unlearning.NOISY_GRADIENT_DESCENT: 2>: {'lr': 0.001, 'epochs': 1, 'noise_scale': 0.00031622776601683794}, <Unlearning.GRADIENT_ASCENT: 1>: {'lr': 1e-05, 'epochs': 1}, <Unlearning.NEG_GRAD_PLUS: 3>: {'lr': 0.001, 'beta': 0.999, 'epochs': 1}, <Unlearning.CFK: 4>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.EUK: 5>: {'k': 6, 'lr': 0.001, 'epochs': 0}, <Unlearning.SCRUB: 6>: {'max_steps': 1, 'steps': 1, 'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9}})\n",
      "Poisoning GradientInverter(method=Gradient Ascent, estimator=ShadowGradientEstimator(aux_loader = DataLoader(<data_len=5000>)), steps=5, tv_coef=0.0, lr=0.3, sample_init=SampleInitRandomNoise(), label_update_schedule=PowerofTwoSchedule()) with hparams=Hyperparams(lr=0.001, weight_decay=0.0005, max_lr=0.1, batch_size=100, epochs=1, num_classes=10, top_k=1, criterion=CrossEntropyLoss()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3babada40b4e5cbc57ce5869a923f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train epochs:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab970dca109d47d5ab5cb983c1cc7d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train loop:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poisoned, poison_results = poison(\n",
    "    ShuffleNetV2,\n",
    "    aggregator = Krum.with_learning_settings(batch_size, tol = 0.05),\n",
    "    inversion_method = GradientAttack.ASCENT,\n",
    "    poison_factor = 0.05,\n",
    "    training_hparams = dict(epochs=1),\n",
    "    quicktesting=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning + unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner, poison_unlearn_results = poison_and_unlearn(\n",
    "    ShuffleNetV2,\n",
    "    aggregator = Mean(),\n",
    "    inversion_method = GradientAttack.ASCENT,\n",
    "    poison_factor = 0.05,\n",
    "    unlearning_method = Unlearning.NEG_GRAD_PLUS,\n",
    "    training_hparams = dict(epochs=1),\n",
    "    unlearning_hparams = dict(),\n",
    "    quicktesting=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "\n",
    "def plot_accuracy(\n",
    "        train_metrics: list[dict[str, Metric]],\n",
    "        val_metrics: list[dict[str, Metric]] = None,\n",
    "        ax: plt.Axes = None,\n",
    "    ):\n",
    "    # Mean accuracy per step\n",
    "    # TODO: plot moving average or epoch tracking average instead\n",
    "    train_acc_per_step_per_epoch = [\n",
    "        epoch_metrics['MetricTracker'].compute_all()['accuracy'].mean(dim=1)\n",
    "        for epoch_metrics in train_metrics\n",
    "    ]\n",
    "    train_acc_per_step = torch.cat(train_acc_per_step_per_epoch).numpy(force=True)\n",
    "    ax.plot(np.arange(len(train_acc_per_step)), train_acc_per_step, label='Train accuracy')\n",
    "    \n",
    "    if val_metrics:\n",
    "        val_acc_per_step_per_epoch = torch.vstack([\n",
    "            epoch_metrics['MetricTracker'].compute_all()['accuracy'].mean(dim=1)\n",
    "            for epoch_metrics in val_metrics\n",
    "        ]).numpy(force=True)\n",
    "        val_acc_per_epoch = val_acc_per_step_per_epoch.mean(axis=1)\n",
    "        val_acc_std_per_epoch = val_acc_per_step_per_epoch.std(axis=1)\n",
    "\n",
    "        epoch_end_steps = np.cumsum(list(map(len, train_acc_per_step_per_epoch)))\n",
    "        ax.scatter(epoch_end_steps, val_acc_per_epoch, label='Validation accuracy', c='orange')\n",
    "        ax.errorbar(epoch_end_steps, val_acc_per_epoch, yerr=val_acc_std_per_epoch, c='orange')\n",
    "    \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Mean accuracy\")\n",
    "    ax.set_ylim((0.0, 1.0))\n",
    "    ax.legend()\n",
    "\n",
    "def display_logs(logs: Logs, ax: plt.Axes):\n",
    "    plot_accuracy(logs.train_metrics, logs.val_metrics, ax=ax)\n",
    "\n",
    "def display_pipeline_results(results: PipelineResults):\n",
    "    if results.unlearning:\n",
    "        assert results.poisoning\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        display_logs(results.train_logs, ax=axes[0])\n",
    "        axes[0].set_title(\"Training accuracy (poisoning)\")\n",
    "\n",
    "        display_logs(results.unlearn_logs, ax=axes[1])\n",
    "        axes[1].set_title(\"Training accuracy (unlearning)\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "    \n",
    "    else:\n",
    "        ax = plt.subplot()\n",
    "        display_logs(results.train_logs, ax=ax)\n",
    "\n",
    "        label = \"poisoning\" if results.poisoning else \"clean\"\n",
    "        ax.set_title(f\"Training accuracy ({label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pipeline_results(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning (no defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pipeline_results(poison_no_defense_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(poisoned_no_defense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning + robust aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pipeline_results(poison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(poisoned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisoning + unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pipeline_results(poison_unlearn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(unlearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment on the results, are they expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing gradient estimation with auxiliary dataset\n",
    "\n",
    "We test the estimation quality of the average clean gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gradient_estimation(\n",
    "        model: nn.Module,\n",
    "        train: bool = True,\n",
    "        momentum: float = 0.9,\n",
    "    ) -> list[float]:\n",
    "    model = deepcopy(model)\n",
    "    model.train(train)\n",
    "    estimator = ShadowGradientEstimator(aux_loader, momentum=momentum)\n",
    "    omniscient = OmniscientGradientEstimator()\n",
    "\n",
    "    mini_train_set = random_split(training_data, [0.4, 0.6])[0]\n",
    "    mini_train_loader = DataLoader(mini_train_set, batch_size=batch_size)\n",
    "    optimizer = Adam(model.parameters())\n",
    "\n",
    "    scores = []\n",
    "    for X, y in mini_train_loader:\n",
    "        X, y = X.to(BEST_DEVICE), y.to(BEST_DEVICE)\n",
    "        criterion(model(X), y).backward()\n",
    "        g_true = omniscient.average_clean_gradient(model, criterion)\n",
    "        if train:\n",
    "            optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        g_pred = estimator.average_clean_gradient(model, criterion)\n",
    "\n",
    "        cos_sim = torch.cosine_similarity(g_true, g_pred, dim=0).item()\n",
    "        scores.append(cos_sim)\n",
    "    return scores\n",
    "\n",
    "def show_scores(scores: list[float], ax: plt.Axes):\n",
    "    ax.plot(scores)\n",
    "    ax.hlines(np.mean(scores), 0, len(scores), color='orange')\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Cosine similarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_estimation_comparison(model: nn.Module):\n",
    "    fig, axes = plt.subplots(1, 5, sharey=True)\n",
    "    fig.set_figwidth(12)\n",
    "\n",
    "    momentum = 0.9\n",
    "    scores_1 = eval_gradient_estimation(model, train=False, momentum=momentum)\n",
    "    show_scores(scores_1, ax=axes[0])\n",
    "    axes[0].set_title(f\"No training\\nmomentum: {momentum}\")\n",
    "\n",
    "    scores_2 = eval_gradient_estimation(model, momentum=momentum)\n",
    "    show_scores(scores_2, ax=axes[1])\n",
    "    axes[1].set_title(f\"Training\\nmomentum: {momentum}\")\n",
    "\n",
    "    momentum = 0.7\n",
    "    scores_3 = eval_gradient_estimation(model, train=False, momentum=momentum)\n",
    "    show_scores(scores_3, ax=axes[2])\n",
    "    axes[2].set_title(f\"No training\\nmomentum: {momentum}\")\n",
    "\n",
    "    scores_4 = eval_gradient_estimation(model, momentum=momentum)\n",
    "    show_scores(scores_4, ax=axes[3])\n",
    "    axes[3].set_title(f\"Training\\nmomentum: {momentum}\")\n",
    "\n",
    "    scores_5 = eval_gradient_estimation(model, momentum=0.0)\n",
    "    show_scores(scores_5, ax=axes[4])\n",
    "    axes[4].set_title(f\"Training\\nno momentum\")\n",
    "\n",
    "    fig.suptitle(\"True batch gradient vs. estimated average gradient\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_estimation_comparison(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
