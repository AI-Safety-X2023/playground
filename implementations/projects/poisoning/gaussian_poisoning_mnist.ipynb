{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Machine Unlearning against Gaussian data poisoning\n",
    "\n",
    "This is a sample implementation of gaussian data poisoning as described by the AI Security paper [Machine Unlearning Fails to Remove Data Poisoning Attacks\n",
    "](https://arxiv.org/abs/2406.17216)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _Loss, CrossEntropyLoss\n",
    "from torch.optim import Optimizer, SGD, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import ResNet, resnet18\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from image_classification.utils import seed_all_generators, use_tqdm\n",
    "from image_classification.accel import BEST_DEVICE, optimize_model\n",
    "from image_classification.datasets import EagerDataset, mnist_train_test\n",
    "from image_classification.nn import (\n",
    "    train_loop,\n",
    "    test_epoch,\n",
    ")\n",
    "from image_classification.gaussian_poisoning import (\n",
    "    GaussianPoisoningDataset,\n",
    "    gaussian_unlearning_score,\n",
    ")\n",
    "from image_classification.unlearning import (\n",
    "    gradient_descent,\n",
    "    gradient_ascent,\n",
    "    neg_grad_plus,\n",
    "    oracle_unlearning,\n",
    "    unlearning_last_layers,\n",
    "    scrub,\n",
    "    NoisySGD,\n",
    ")\n",
    "\n",
    "# For deterministic results\n",
    "seed_all_generators(0x2023_2024)\n",
    "\n",
    "# NOTE: Don't forget to clear all outputs in vscode before running.\n",
    "# \n",
    "# WARNING (Windows): consider setting ascii=True and installing vscode-tqdm\n",
    "# if notebook display issues persist: https://pypi.org/project/vscode-tqdm/\n",
    "# Alternatively, set enable=False (but there won't be interactive output).\n",
    "use_tqdm(enable=True, ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work on the MNIST handwritten digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = mnist_train_test(root='data')\n",
    "\n",
    "N = len(training_data)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.data\n",
    "y = training_data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poison the training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attacker poisons a fraction $\\varepsilon$ of the features with noise $(\\xi_z)_{z \\in S_\\mathrm{poison}}$ and stores the noise for future usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data standard deviation: 1\n",
      "Noise standard deviation: 0.1\n",
      "Noise data for poisoning: torch.Size([11912, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# FIXME: for linear regression, we need very high values\n",
    "# to observe the effect of data poisoning\n",
    "poison_budget = 0.2\n",
    "# TODO: lower noise value\n",
    "noise_std = 0.1 * X.std().item()\n",
    "\n",
    "corrupted_dataset = GaussianPoisoningDataset(\n",
    "    training_data,\n",
    "    poison_budget,\n",
    "    noise_std,\n",
    ")\n",
    "\n",
    "S_poison: Tensor[bool] = corrupted_dataset.poison_support\n",
    "N_poison = corrupted_dataset.num_poisons()\n",
    "N_clean = N - N_poison\n",
    "\n",
    "y_base: Tensor = y[S_poison.cpu()]\n",
    "X_base: Tensor = corrupted_dataset.clean_dataset.data[S_poison]\n",
    "X_poison: Tensor = corrupted_dataset.data[S_poison]\n",
    "poisoning_noise: Tensor = corrupted_dataset.noise[S_poison]\n",
    "\n",
    "# Another independent standard noise used as a baseline for unlearning evaluation\n",
    "# (not used to corrupt the dataset)\n",
    "dummy_noise = noise_std * torch.randn_like(poisoning_noise)\n",
    "\n",
    "print(f'Clean data standard deviation: {X_base.std().item():.2g}')\n",
    "print(f'Noise standard deviation: {poisoning_noise.std().item():.2g}')\n",
    "print('Noise data for poisoning:', poisoning_noise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_input_image(input: Tensor, class_: Tensor, title='', cmap=plt.cm.gray):\n",
    "    \"\"\"\n",
    "    Displays an an input image to a neural network.\n",
    "\n",
    "    `input`: a 3D tensor\n",
    "    `cmap`: grayscale by default.\n",
    "    \"\"\"\n",
    "    image = input[0].to('cpu').detach()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image, cmap=cmap, interpolation='nearest')\n",
    "    plt.title(str(class_.item()))\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300.485pt\" height=\"341.886125pt\" viewBox=\"0 0 300.485 341.886125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-01-25T20:24:40.900259</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.5, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 341.886125 \n",
       "L 300.485 341.886125 \n",
       "L 300.485 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 318.008 \n",
       "L 293.285 318.008 \n",
       "L 293.285 51.648 \n",
       "L 26.925 51.648 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pd8047b5b11)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imagec0f30cd51b\" transform=\"scale(1 -1) translate(0 -266.4)\" x=\"26.925\" y=\"-51.608\" width=\"266.4\" height=\"266.4\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m9bd0082421\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"31.681429\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(28.500179 332.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"79.245714\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(76.064464 332.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"126.81\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(120.4475 332.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"174.374286\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(168.011786 332.606437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"221.938571\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(215.576071 332.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9bd0082421\" x=\"269.502857\" y=\"318.008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(263.140357 332.606437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"me4d47aed2c\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"56.404429\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 60.203647) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"103.968714\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 107.767933) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"151.533\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 155.332219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"199.097286\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 202.896504) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"246.661571\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 250.46079) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#me4d47aed2c\" x=\"26.925\" y=\"294.225857\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 298.025076) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 318.008 \n",
       "L 26.925 51.648 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 293.285 318.008 \n",
       "L 293.285 51.648 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 318.008 \n",
       "L 293.285 318.008 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 51.648 \n",
       "L 293.285 51.648 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <!-- 2 -->\n",
       "    <g transform=\"translate(156.2875 45.648) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"text_14\">\n",
       "   <!-- Original image -->\n",
       "   <g transform=\"translate(108.684531 17.837812) scale(0.14 -0.14)\">\n",
       "    <defs>\n",
       "     <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1225 4090 567 \n",
       "Q 3503 -91 2522 -91 \n",
       "Q 1538 -91 948 565 \n",
       "Q 359 1222 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "    </defs>\n",
       "    <use xlink:href=\"#DejaVuSans-4f\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-72\" x=\"78.710938\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-69\" x=\"119.824219\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-67\" x=\"147.607422\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-69\" x=\"211.083984\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-6e\" x=\"238.867188\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-61\" x=\"302.246094\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-6c\" x=\"363.525391\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-20\" x=\"391.308594\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-69\" x=\"423.095703\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-6d\" x=\"450.878906\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-61\" x=\"548.291016\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-67\" x=\"609.570312\"/>\n",
       "    <use xlink:href=\"#DejaVuSans-65\" x=\"673.046875\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd8047b5b11\">\n",
       "   <rect x=\"26.925\" y=\"51.648\" width=\"266.36\" height=\"266.36\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_input_image(X_base[0], y_base[0], title='Original image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_input_image(\n",
    "    X_poison[0], y_base[0],\n",
    "    title=f'Poisoned image with {int(100 * noise_std)} % gaussian noise'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the amplitude of added noise, the image is still recognizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the poisoned data and the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate correlation between the `kx` coordinate of the samples `X`\n",
    "# and the `ky` coordinate of the samples `Y`.\n",
    "def correlation(X: Tensor, Y: Tensor, kx=0, ky=0):\n",
    "    #return torch.corrcoef(X[:, kx], Y[:, ky])\n",
    "    assert X.shape == Y.shape, f'Shape mismatch: {X.shape}, {Y.shape}'\n",
    "    X = X.flatten(start_dim=1)\n",
    "    Y = Y.flatten(start_dim=1)\n",
    "    return np.corrcoef(X[:, kx].numpy(force=True), Y[:, ky].numpy(force=True), rowvar=False)\n",
    "\n",
    "print(\n",
    "    'Correlation matrix of clean samples and poisons\\n',\n",
    "    correlation(X_base, poisoning_noise)\n",
    ")\n",
    "print(\n",
    "    'Correlation matrix of poisoned samples and fresh gaussians\\n',\n",
    "    correlation(X_base, dummy_noise)\n",
    ")\n",
    "print(\n",
    "    'Correlation matrix of poisoned samples and poisons\\n',\n",
    "    correlation(X_poison, poisoning_noise)\n",
    ")\n",
    "print(\n",
    "    'Correlation matrix of fresh gaussians and poisons\\n',\n",
    "    correlation(dummy_noise, poisoning_noise)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defender unknowingly collects corrupted data, which contains a small fraction of poisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we consider the following scenario :\n",
    "1. The defender trains the model on the corrupted dataset.\n",
    "2. The defender realizes afterwards they have been poisoned, and is able to determine which part of the dataset has been corrupted.\n",
    "3. The defender runs the unlearning algorithm on the poisoned dataset.\n",
    "\n",
    "We may also study a stronger relaxation of step 2 with the hypothesis that the defender is able to determine the exact values of the poisons. This unrealistic scenario may be used to prove that Machine Unlearning is necessarily vulnerable to data poisoning. Indeed, if Machine Unlearning fails with such strong assumptions, we may conclude the effect of data poisoning on the model parameters is simply irreversible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model architecture\n",
    "\n",
    "We use a convolutional neural network classifier on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(num_classes=10)\n",
    "        # Change the first convolution layer in order to accept a single channel\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(\n",
    "            1, 64, \n",
    "            kernel_size=(7, 7), \n",
    "            stride=(2, 2), \n",
    "            padding=(3, 3),\n",
    "            bias=False,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet.forward(x).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistResNet().to(BEST_DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean sets, corrupted sets and poisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The retain set\n",
    "clean_subset = corrupted_dataset.clean_subset()\n",
    "clean_loader = DataLoader(clean_subset, batch_size)\n",
    "\n",
    "# The forget set\n",
    "poisoned_subset = corrupted_dataset.poisoned_subset()\n",
    "poisoned_loader = DataLoader(poisoned_subset, batch_size)\n",
    "\n",
    "# The forget set before poisoning\n",
    "base_subset = corrupted_dataset.clean_subset_before_poisoning()\n",
    "base_loader = DataLoader(base_subset, batch_size)\n",
    "\n",
    "# The clean test set\n",
    "test_loader = DataLoader(test_data, batch_size)\n",
    "\n",
    "# The corrupted set (clean and poisons)\n",
    "corrupted_loader = DataLoader(corrupted_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 0.0\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "loss_func = CrossEntropyLoss()\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model: nn.Module, lr=lr, weight_decay=weight_decay) -> Optimizer:\n",
    "    return AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_model = deepcopy(model)\n",
    "opt = make_optimizer(clean_model)\n",
    "train_loop(clean_model, clean_loader, loss_func, opt, epochs=epochs)\n",
    "test_epoch(clean_model, test_loader, loss_func, keep_pbars=True, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_model = deepcopy(model)\n",
    "opt = make_optimizer(corrupted_model)\n",
    "train_loop(corrupted_model, corrupted_loader, loss_func, opt, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect_model(corrupted_model)\n",
    "\n",
    "# FIXME: loss shouldn't be strictly equal to zero\n",
    "print('\\n\\nOn the clean subset:')\n",
    "test_epoch(corrupted_model, clean_loader, loss_func, keep_pbars=True, metric=metric)\n",
    "\n",
    "print('\\n\\nOn the (clean) test set:')\n",
    "test_epoch(corrupted_model, test_loader, loss_func, keep_pbars=True, metric=metric)\n",
    "\n",
    "print('\\n\\nOn the original version of the poisoned subset before poisoning:')\n",
    "test_epoch(corrupted_model, base_loader, loss_func, keep_pbars=True, metric=metric)\n",
    "\n",
    "print('\\n\\nOn the poisoned subset:')\n",
    "test_epoch(corrupted_model, poisoned_loader, loss_func, keep_pbars=True, metric=metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite remarkable that the model actually performs better on the clean dataset than the corrupted dataset, even though it was trained on the corrupted one. This means the model did not really learn the noise (did not overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are model outputs correlated to the noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_model(X_poison).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_noise.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: use spearman rank correlation coef. ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    print(\n",
    "#        'Correlation matrix of model outputs (before unlearning) and fresh noise\\n',\n",
    "#        correlation(corrupted_model(X_poison), dummy_noise)\n",
    "#    )\n",
    "#    print(\n",
    "#        'Correlation matrix of model outputs (before unlearning) and poisoning noise\\n',\n",
    "#        correlation(corrupted_model(X_poison), poisoning_noise)\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nope! But this computation does not make sense!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model shift with poisoning\n",
    "\n",
    "TODO: prove that model update direction is orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_tensor(model: nn.Module) -> Tensor:\n",
    "    params = [\n",
    "        param.detach().flatten()\n",
    "        for param in model.parameters()\n",
    "    ]\n",
    "    return torch.cat(params)\n",
    "\n",
    "def model_gradients(model: nn.Module) -> Tensor:\n",
    "    params = [\n",
    "        param.grad.detach().flatten()\n",
    "        for param in model.parameters()\n",
    "    ]\n",
    "    return torch.cat(params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corrupted_dataset(\n",
    "        poison_budget: float,\n",
    "        eps: float = noise_std,\n",
    "    ) -> GaussianPoisoningDataset:\n",
    "    return GaussianPoisoningDataset(\n",
    "        training_data,\n",
    "        poison_budget,\n",
    "        eps,\n",
    "    )\n",
    "\n",
    "def train_new_model_on(\n",
    "        dataset: Dataset,\n",
    "    ) -> MnistResNet:\n",
    "    corrupted_loader = DataLoader(dataset, batch_size)\n",
    "\n",
    "    poisoned_model = MnistResNet().to(BEST_DEVICE)\n",
    "    opt = make_optimizer(poisoned_model, lr=5e-3)\n",
    "    train_loop(poisoned_model, corrupted_loader, loss_func, opt, epochs=epochs, keep_pbars=False)\n",
    "\n",
    "    return poisoned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_relative_diff(\n",
    "        clean_model: nn.Module,\n",
    "        poisoned_model: nn.Module,\n",
    "    ) -> float:\n",
    "    clean_model.eval()\n",
    "    poisoned_model.eval()\n",
    "\n",
    "    theta_corr = model_to_tensor(poisoned_model)\n",
    "    theta_clean = model_to_tensor(clean_model)\n",
    "    diff = torch.norm(theta_corr - theta_clean, 1)\n",
    "    return (diff / torch.norm(theta_clean, 1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relative_diff(clean_model, corrupted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def model_shift_against_poison_budget(n=30):\n",
    "    poison_budgets = np.linspace(0.0, 1.0, n)\n",
    "    rows = []\n",
    "    for poison_budget in tqdm(poison_budgets, desc='Poison budget'):\n",
    "        corrupted_data = make_corrupted_dataset(poison_budget)\n",
    "        poisoned_model = train_new_model_on(corrupted_data)\n",
    "        model_shift = model_relative_diff(clean_model, poisoned_model)\n",
    "        rows.append([poison_budget, model_shift])\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=['poison_budget', 'model_shift'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_shift_against_poison_budget(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line(x='poison_budget', y='model_shift')\n",
    "plt.xlabel('Poison budget')\n",
    "plt.ylabel('Model shift relative to clean model')\n",
    "plt.title('Corrupted model shift against poison budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME: this is not coherent with the order of magnitude of the previous value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_5_a(\n",
    "        clean_model: nn.Module,\n",
    "        poisoned_model: nn.Module,\n",
    "        clean_loader: DataLoader,\n",
    "        loss_fn: _Loss,\n",
    "    ):\n",
    "    clean_model.eval()\n",
    "    poisoned_model.eval()\n",
    "\n",
    "    cos_sims = []\n",
    "\n",
    "    theta_clean = model_to_tensor(clean_model)\n",
    "\n",
    "    #def grad_hook(model: nn.Module, grad_input):\n",
    "    #    theta = model_to_tensor(model)\n",
    "    #    g = model_gradients(model)\n",
    "    #    v = theta - theta_clean\n",
    "    #    cos_sims.append(torch.cosine_similarity(v, g, dim=0).item())\n",
    "\n",
    "    #handle = poisoned_model.register_full_backward_pre_hook(grad_hook)\n",
    "\n",
    "    for X_b, y_b in clean_loader:\n",
    "        loss = loss_fn(poisoned_model(X_b), y_b)\n",
    "        loss.backward()\n",
    "\n",
    "        g = model_gradients(poisoned_model)\n",
    "        v = model_to_tensor(poisoned_model) - theta_clean\n",
    "        cos_sims.append(torch.cosine_similarity(v, g, dim=0).item())\n",
    "    \n",
    "    cos_sims = np.array(cos_sims)\n",
    "\n",
    "    #handle.remove()\n",
    "\n",
    "    plt.hist(cos_sims, bins='rice')\n",
    "    plt.xlabel(fr'$\\langle v, g_t \\rangle / \\Vert v \\Vert \\Vert g_t \\Vert$')\n",
    "    \n",
    "    axes = plt.gca()\n",
    "    axes.xaxis.set_major_formatter('{x:.1e}')\n",
    "\n",
    "    plt.title(fr'Cosine similarity between batch gradient updates and clean vs. poison model shift')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_5_a(clean_model, corrupted_model, clean_loader, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: after poisoning, the model shift is orthogonal to the batch gradient updates, which means gradient-based methods fail to effectively unlearn the noise.\n",
    "\n",
    "TODO: give a mathematical explanation for simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Unlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent (GD)\n",
    "\n",
    "> GD continues to train the model $\\theta_{\\mathrm{initial}}$ on the\n",
    "remaining dataset $S_{\\mathrm{train}} \\setminus U$ by using gradient descent. In particular, we obtain $\\theta_{\\mathrm{updated}}$ via\n",
    "> \n",
    "> $\\theta_{t+1} \\gets \\theta_t − \\eta g_t (\\theta_t)$ with $\\theta_1 = \\theta_{\\mathrm{initial}}$\n",
    "> \n",
    "> where $\\eta$ denotes the step size and $g_t$ denotes a (mini-batch) gradient computed for the the training\n",
    "loss $\\widehat{\\mathbb{E}}_{(x,y) \\in S_{\\mathrm{train}} \\setminus U} \\left[l((x, y), \\theta)\\right]$ defined using the remaining dataset $S_{\\mathrm{train}} \\setminus U$, where $l$ is a loss function, e.g., cross-entropy loss, hinge loss, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Ascent (GA)\n",
    "\n",
    "> GA is an unlearning algorithm which attempts to remove the influence of the forget set $U$ from the trained model by simply reversing the gradient updates that contain information about $U$. In particular, we update via\n",
    "> \n",
    "> $\\theta_{t+1} \\gets \\theta_t + \\eta g_t (\\theta_t)$ with $\\theta_1 = \\theta_{\\mathrm{initial}}$\n",
    "> \n",
    "> where $g_t$ denotes a (mini-batch) gradient computed for the the training loss $\\widehat{\\mathbb{E}}_{(x,y) \\in U} \\left[l((x, y), \\theta)\\right]$ on the deletion\n",
    "set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the effect of Gaussian data poisoning\n",
    "\n",
    "We follow the *Algorithm 3* in the original paper of Pawelczyk et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the computed standard deviation might not be 1 due to gradient vanishing\n",
    "def evaluate_unlearning(\n",
    "        model: nn.Module,\n",
    "        base_data: Dataset,\n",
    "        noise: Dataset,\n",
    "        noise_std: float,\n",
    "        loss_fn: _Loss,\n",
    "        xi_name=r'$\\xi$', g_name='g', method='',\n",
    "    ):\n",
    "    I_poison = gaussian_unlearning_score(\n",
    "        model,\n",
    "        base_data,\n",
    "        noise,\n",
    "        noise_std,\n",
    "        loss_fn,\n",
    "    )\n",
    "\n",
    "    mean = I_poison.mean()\n",
    "    std = I_poison.std()\n",
    "\n",
    "    mean_std_theory = 1. / np.sqrt(float(len(noise)))\n",
    "\n",
    "    plt.hist(I_poison, density=True)\n",
    "\n",
    "    iz = np.linspace(I_poison.min(), I_poison.max())\n",
    "    distr = stats.norm(mean, std)\n",
    "    plt.plot(iz, distr.pdf(iz), label=fr'Gaussian fit: $\\mathcal{{N}}({mean:.3}, {std**2:.3})$')\n",
    "    \n",
    "    distr = stats.norm(0.0, 1.0)\n",
    "    plt.plot(iz, distr.pdf(iz), label=fr'Theory: $\\mathcal{{N}}(0 \\pm {mean_std_theory:.3g}, 1)$')\n",
    "\n",
    "    plt.xlabel(fr'$\\mathcal{{I}}_{{\\mathrm{{poison}}}} = \\frac{{\\langle \\xi, {g_name} \\rangle}}{{\\epsilon ||{g_name}||_2}}$')\n",
    "    plt.title(fr'Normalized dot product distribution between input gradients ${g_name}$ and {xi_name}')\n",
    "    if method:\n",
    "        plt.suptitle(method)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import image_classification.gaussian_poisoning\n",
    "reload(image_classification.gaussian_poisoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_classification.gaussian_poisoning import gaussian_unlearning_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_no_reduction = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "evaluate_unlearning(\n",
    "    corrupted_model, base_subset, dummy_noise, noise_std, loss_func_no_reduction,\n",
    "    xi_name=r'fresh gaussians $\\tilde{\\xi}$', g_name=r'g_{\\mathrm{initial}}', method='Independent noise'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When testing against independent noise, the result should be equivalent to perfect unlearning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_unlearning(\n",
    "    corrupted_model, base_subset, poisoning_noise, noise_std, loss_func_no_reduction,\n",
    "    xi_name=r'poisons $\\xi$', g_name=r'g_{\\mathrm{initial}}', method='No unlearning'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fresh Gaussians, the distribution should be centered around $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data poisoning, the model gradients are influenced by $\\xi$ so the distribution is shifted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME: actually, there is very little correlation because the model seems to have minimized the loss over the clean samples rather than the poisoned samples, which is why the loss gradient is not correlated with the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate unlearning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the previous distribution again, after running the unlearning algorithm.\n",
    "If the distribution is still shifted, that means the model did not perfectly unlearn the poisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_post_unlearning_results(model: nn.Module, algo_name: str):\n",
    "    print('\\n\\nTest on clean samples:')\n",
    "    test_epoch(model, test_loader, loss_func, keep_pbars=True, metric=metric)\n",
    "    print('\\n\\nTest on poisoned samples:')\n",
    "    test_epoch(model, poisoned_loader, loss_func, keep_pbars=True, metric=metric)\n",
    "    print('\\n\\n')\n",
    "    evaluate_unlearning(\n",
    "        model, base_subset, poisoning_noise, noise_std, loss_func_no_reduction,\n",
    "        xi_name=r'Gaussian poisons $\\xi$',\n",
    "        g_name=r'g_{\\mathrm{updated}}',\n",
    "        method=algo_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "opt_gd = make_optimizer(unlearner, lr=0.5 * lr)\n",
    "gradient_descent(unlearner, clean_loader, test_loader, loss_func, opt_gd, epochs=1)\n",
    "display_post_unlearning_results(unlearner, algo_name='Gradient descent unlearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "opt_ngd = NoisySGD(unlearner.parameters(), noise_scale=np.sqrt(1e-6), lr=1e-1)\n",
    "gradient_descent(unlearner, clean_loader, test_loader, loss_func, opt_gd, epochs=1)\n",
    "display_post_unlearning_results(unlearner, algo_name='Noisy gradient descent unlearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "opt_ga = make_optimizer(unlearner, lr=0.1 * lr)\n",
    "gradient_ascent(unlearner, clean_loader, test_loader, loss_func, opt_ga, epochs=epochs)\n",
    "display_post_unlearning_results(unlearner, algo_name='Gradient ascent unlearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient ascent completely fails to maintain a good overall performance. Seems like the algorithm is overfitting on unlearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NegGrad+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "opt_ngp = make_optimizer(unlearner, lr=lr)\n",
    "neg_grad_plus(unlearner, clean_loader, poisoned_loader, loss_func, opt_ngp, beta=0.995)\n",
    "display_post_unlearning_results(unlearner, algo_name='NegGrad+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle unlearning (ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "# TODO:\n",
    "# Future work: how to set learning rate according to GUS? Is GUS a relevant metric?\n",
    "opt_oracle = make_optimizer(unlearner, lr=0.1 * lr)\n",
    "\n",
    "oracle_unlearning(unlearner, base_loader, poisoned_loader, loss_func, opt_oracle)\n",
    "display_post_unlearning_results(unlearner, algo_name='Oracle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CFk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "with unlearning_last_layers(unlearner, 1, mode='cfk'):\n",
    "    opt_cfk = make_optimizer(unlearner, lr=0.5 * lr)\n",
    "    train_loop(unlearner, clean_loader, loss_func, opt_cfk, epochs=1)\n",
    "display_post_unlearning_results(unlearner, algo_name='CFk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EUk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearner = deepcopy(corrupted_model)\n",
    "with unlearning_last_layers(unlearner, 1, mode='euk'):\n",
    "    opt_euk = make_optimizer(unlearner, lr=0.5 * lr)\n",
    "    train_loop(unlearner, clean_loader, loss_func, opt_euk, epochs=epochs)\n",
    "display_post_unlearning_results(unlearner, algo_name='EUk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = deepcopy(corrupted_model)\n",
    "student = deepcopy(teacher)\n",
    "opt_scrub = make_optimizer(unlearner, lr=lr)\n",
    "scrub(\n",
    "    teacher, student,\n",
    "    clean_loader, poisoned_loader,\n",
    "    loss_func, opt_scrub,\n",
    "    max_steps=epochs, steps=epochs,\n",
    ")\n",
    "display_post_unlearning_results(unlearner, algo_name='SCRUB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Disclaimer: the experiment results do not provide strong evidence.\n",
    "\n",
    "Ablation study :\n",
    "\n",
    "- Larger models are more vulnerable to data poisoning. Indeed, when the model dimension is very high compared to the feature dimension, the model is likely to overfit on the poisons, therefore making them hard to forget.\n",
    "- Data poisoning has a larger effect on high-dimensioned data. We should adapt our experiment to images to see the difference.\n",
    "- For simple problems such as linear regression, the effect of data poisoning seems to decrease as the number of samples grows. To get an intuition of why this is true, consider the $1$-dimensional linear regression: the estimated slope coefficient converges to the true slope coefficient, even if the training data is poisoned.\n",
    "- Techniques such as gradient ascent unlearning (GA) are more efficient at removing poisons, however the model becomes widly inaccurate on the base dataset. This highlights the tradeoff between privacy and usefulness. For unlearning, we need to make a compromise between GD and GA."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
